---
title: "[MIT Technolgy Reviews] The messy, secretive reality behind OpenAI’s bid to save the world (4부)"
categories:
  - AI Regulation
tags:
  - OpenAI
  - AI
  - MIT Technolgy Reviews
  - Reliable AI
#  - AI policy
#  - news scraps
  - 인공지능
  - 안전
  - 신뢰
#  - 정책

last_modified_at: 2023-12-01T15:00:11-15:10
---
_________________

ARTIFICIAL INTELLIGENCE

# The messy, secretive reality behind OpenAI’s bid to save the world

#### The AI moonshot was founded in the spirit of transparency. This is the inside story of how competitive pressure eroded that idealism.

##### By Karen Hao
##### February 17, 2020
---


  * MIT Technolgy Reviews에 2020년 2월 17일, AI분야 기자 [Karen Hao](https://www.technologyreview.com/author/karen-hao/)이 작성한 [기사](https://www.technologyreview.com/2020/02/17/844721/ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality/)를 DeepL로 번역 후, "포괄적 요약"하고, "저의 의견"을 추가하여 작성한 내용
  * 2022년 ChatGPT로 일반인들(나 포함)에게 알려지기 까지, 2019년 2020년 초에 OpenAI가 어떤 기업이였는지 알 수 있는 자료
  * 만약 저작권에 문제가 있다면 바로 알려주세요!!

---

#### 연구 책임자 '다리오 아모데이' 그리고 연구 분위기

OpenAI의 전략을 주도하는 사람은 구글러 출신으로 현재 연구 책임자로 일하고 있는 다리오 아모데이입니다. 처음 만났을 때 그는 브록맨보다 더 불안한 사람으로 보였습니다. 성실함과 감수성은 비슷하지만 불안한 신경 에너지가 느껴집니다. 그는 말을 할 때 미간을 찌푸린 채 무심코 곱슬머리를 잡아당기는 손으로 먼 곳을 응시합니다.

아모데이는 연구소의 전략을 두 부분으로 나눕니다. 첫 번째 부분은 고급 AI 기능에 도달하기 위한 계획으로, 그는 이를 투자자의 "베팅 포트폴리오"에 비유합니다. OpenAI의 각 팀은 서로 다른 베팅을 하고 있습니다. 예를 들어 언어 팀은 AI가 단순한 언어 학습을 통해 세상에 대한 상당한 이해력을 키울 수 있다는 가설에 돈을 걸고 있습니다. 반면 로봇 팀은 지능이 발달하려면 물리적 구현이 필요하다는 반대 이론을 발전시키고 있습니다.

투자자의 포트폴리오에서와 마찬가지로 모든 베팅이 동일한 비중을 가지는 것은 아닙니다. 하지만 과학적 엄밀성을 위해 모든 베팅은 버리기 전에 테스트를 거쳐야 합니다. 아모데이는 놀랍도록 사실적인 자동 생성 텍스트를 제공하는 GPT-2를 열린 마음을 유지하는 것이 중요한 이유를 보여주는 사례로 꼽았습니다. "순수 언어는 현장에서는 물론 우리 중 일부도 다소 회의적이었던 방향입니다."라고 그는 말합니다. "하지만 지금은 '와, 정말 유망하구나'라는 생각이 들었습니다."

시간이 지남에 따라 서로 다른 베팅이 다른 베팅보다 우위를 점하게 되면 더 많은 노력을 기울이게 될 것입니다. 그러면 서로 교차 수분하고 결합할 것입니다. 목표는 점점 더 적은 수의 팀이 궁극적으로 AGI의 단일 기술 방향으로 수렴하는 것입니다. 이것이 바로 OpenAI의 최신 극비 프로젝트가 이미 시작한 것으로 추정되는 정확한 과정입니다.

<figure>
    <img src="https://cdn.technologyreview.com/i/images/cf3a2296final.jpg?sw=700&cx=0&cy=193&cw=1355&ch=1807"
         alt="Dario Amodei">
    <figcaption> <br>Dario Amodei, research director. </br> Christie Hemm Klok </figcaption>
</figure>


아모데이는 이 전략의 두 번째 부분은 이렇게 계속 발전하는 AI 시스템을 안전하게 만드는 방법에 초점을 맞추고 있다고 설명합니다. 여기에는 인간의 가치를 반영하고, 결정의 논리를 설명할 수 있으며, 그 과정에서 사람을 해치지 않고 학습할 수 있도록 하는 것이 포함됩니다. 이러한 각 안전 목표를 전담하는 팀은 프로젝트가 성숙해짐에 따라 프로젝트 전반에 적용할 수 있는 방법을 개발하기 위해 노력합니다. 예를 들어 설명가능성 팀에서 개발한 기술은 GPT-2의 문장 구성이나 로봇의 움직임 뒤에 숨은 논리를 드러내는 데 사용될 수 있습니다.

아모데이는 이 전략의 일부가 이 분야의 확립된 이론에 기반하기보다는 직감에 의존한 다소 우연한 결과물이라고 인정합니다. "언젠가는 AGI를 구축하게 될 텐데, 그때쯤이면 전 세계에서 이러한 시스템이 작동하는 것에 대해 기분이 좋아지고 싶습니다."라고 그는 말합니다. "현재 기분이 좋지 않은 부분이 있다면 그 부분에 집중할 수 있는 팀을 만들고 모집합니다."

홍보와 비밀을 중시하는 아모데이가 이렇게 말할 때면 진심이 느껴집니다. 실패의 가능성은 그를 방해하는 것 같습니다.

"우리는 AGI가 어떤 모습일지 모른다는 어색한 입장에 처해 있습니다."라고 그는 말합니다. "우리는 그것이 언제 일어날지 모릅니다." 그런 다음 그는 조심스럽게 자기 인식을 하면서 이렇게 덧붙입니다: "모든 사람의 마음에는 한계가 있습니다. 제가 찾은 가장 좋은 방법은 제가 생각했던 것과는 다른 비전을 가진 다른 안전 연구원을 고용하는 것이었습니다. 그런 변화와 다양성을 원합니다. 그래야만 모든 것을 파악할 수 있기 때문입니다."

---

문제는 OpenAI에는 실제로 '다양성과 다양성'이 거의 없다는 점입니다. 사무실에 출근한 지 3일째 되던 날 이 사실을 뼈저리게 느꼈습니다. 직원들과 어울릴 수 있는 점심 식사 시간이 주어졌을 때 저는 가장 눈에 띄게 다양한 인종이 모인 테이블에 앉았습니다. 1분도 채 지나지 않아 저는 그곳에서 식사를 하는 사람들이 사실 OpenAI 직원이 아니라는 사실을 깨달았습니다. 컴퓨터와 뇌의 인터페이스를 연구하는 머스크의 스타트업인 뉴럴링크는 같은 건물과 식당을 공유하고 있습니다.

<figure>
    <img src="https://cdn.technologyreview.com/i/images/cf3a2337final.jpg?sw=700&cx=0&cy=0&cw=1333&ch=1777"
         alt="Daniela Amodei">
    <figcaption> <br>Daniela Amodei, head of people operations </br> Christie Hemm Klok </figcaption>
</figure>

연구소 대변인에 따르면 120명이 넘는 직원 중 25%가 여성 또는 논바이너리입니다. 또한 임원진 중 여성은 2명이며 리더십 팀의 여성 비율은 30%라고 그녀는 말했지만, 이 팀에 누가 포함되는지는 구체적으로 밝히지 않았습니다. (브록먼과 알트먼을 포함한 4명의 최고 경영진은 모두 백인 남성입니다. LinkedIn 및 기타 출처에서 확인한 112명 이상의 직원 중 압도적으로 많은 수가 백인이거나 아시아인이었습니다.)

공평하게 말하자면, 이러한 다양성 부족은 AI 업계에서 흔히 볼 수 있는 현상입니다. 지난해 뉴욕에 위치한 연구기관 AI Now의 보고서에 따르면 주요 AI 컨퍼런스의 저자 중 여성은 18%, AI 교수직의 20%, Facebook과 Google의 연구 직원 중 여성은 각각 15%와 10%에 불과한 것으로 나타났습니다. OpenAI의 대변인은 "학계와 업계 전반에 걸쳐 아직 해야 할 일이 많이 남아 있습니다."라고 말했습니다. "다양성과 포용성은 우리가 중요하게 생각하는 부분이며, WiML, 걸 긱, 장학생 프로그램과 같은 이니셔티브와 협력하여 지속적으로 개선하기 위해 노력하고 있습니다."

실제로 OpenAI는 인재 풀을 넓히기 위해 노력해 왔습니다. 2018년에는 소외된 소수민족을 위한 원격 장학생 프로그램을 시작했습니다. 하지만 처음 8명의 장학생 중 단 2명만이 정규직이 되었지만, 이들은 긍정적인 경험을 보고했습니다. 입사 거부의 가장 흔한 이유는 샌프란시스코에 거주해야 한다는 조건이었습니다. 전직 장학생으로 현재 뉴욕에 본사를 둔 회사의 수석 머신러닝 엔지니어로 일하고 있는 나자 로즈에게 샌프란시스코는 다양성이 너무 부족한 도시였습니다.

하지만 다양성이 AI 업계 전반의 문제라면, 기술을 모든 사람에게 골고루 보급하는 것을 사명으로 삼는 기업에게는 더욱 절실한 문제입니다. 소외될 위험이 가장 큰 집단의 대표성이 부족하다는 것이 사실입니다.

또한 브록먼이 자주 언급하는 것처럼 OpenAI가 어떻게 AGI의 혜택을 "모든 인류"에게 "분배"할 계획인지도 명확하지 않습니다. 경영진은 이를 모호한 용어로 표현하고 있으며 구체적인 내용을 거의 밝히지 않고 있습니다. (지난 1월, 옥스퍼드 대학교의 인류의 미래 연구소는 이 연구소와 공동으로 수익의 일정 비율을 분배하여 혜택을 분배할 것을 제안하는 보고서를 발표했습니다. 하지만 저자들은 "이를 구현하는 방식과 관련하여 해결되지 않은 중요한 문제"를 언급했습니다.) 익명을 요구한 한 전직 직원은 "이것이 OpenAI의 가장 큰 문제"라고 말합니다.

<figure>
    <img src="https://cdn.technologyreview.com/i/images/cf3a2401.jpg?sw=700&cx=0&cy=0&cw=3000&ch=2000"
         alt="--">
    <figcaption> <br>DChristie Hemm Klok </figcaption>
</figure>

럿거스 대학의 브릿 패리스는 "인공지능으로 사회 문제에 답하려고 정교한 기술 방식을 사용하고 있습니다."라고 말합니다. "그들은 실제로 사회를 이해할 수 있는 능력이 없는 것 같습니다. 그들은 단지 지금 이 분야가 자신들을 포지셔닝할 수 있는 일종의 수익성 있는 분야라는 것만 알고 있을 뿐입니다."

브록먼은 궁극적으로 OpenAI가 사명을 달성하기 위해서는 기술적 전문성과 사회적 전문성이 모두 필요하다는 데 동의합니다. 하지만 그는 처음부터 사회적 문제를 해결해야 한다는 데는 동의하지 않습니다. "윤리를 비롯한 다른 관점을 정확히 어떻게 도입할 것인가? 그리고 언제 어떻게 도입해야 할까요? 추구할 수 있는 한 가지 전략은 처음부터 필요한 모든 것을 구워 넣는 것입니다."라고 그는 말합니다. "저는 이 전략이 성공할 가능성은 없다고 생각합니다."

그는 가장 먼저 알아내야 할 것은 AGI가 어떤 모습일지 파악하는 것이라고 말합니다. 그런 다음에는 "우리가 그 파급 효과를 제대로 이해하고 있는지 확인"해야 합니다.
