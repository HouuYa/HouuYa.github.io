---
title: "[MIT Technolgy Reviews] The messy, secretive reality behind OpenAI’s bid to save the world (2부)"
categories:
  - AI Regulation
tags:
  - OpenAI
  - AI
  - MIT Technolgy Reviews
  - Reliable AI
#  - AI policy
#  - news scraps
  - 인공지능
  - 안전
  - 신뢰
#  - 정책

last_modified_at: 2023-12-01T15:00:11-15:10
---
_________________

ARTIFICIAL INTELLIGENCE

# The messy, secretive reality behind OpenAI’s bid to save the world

#### The AI moonshot was founded in the spirit of transparency. This is the inside story of how competitive pressure eroded that idealism.

##### By Karen Hao
##### February 17, 2020
---


  * MIT Technolgy Reviews에 2020년 2월 17일, AI분야 기자 [Karen Hao](https://www.technologyreview.com/author/karen-hao/)이 작성한 [기사](https://www.technologyreview.com/2020/02/17/844721/ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality/)를 DeepL로 번역 후, "포괄적 요약"하고, "저의 의견"을 추가하여 작성한 내용
  * 2022년 ChatGPT로 일반인들(나 포함)에게 알려지기 까지, 2019년 2020년 초에 OpenAI가 어떤 기업이였는지 알 수 있는 자료
  * 만약 저작권에 문제가 있다면 바로 알려주세요!!

---

> 2015년 설립 당시, AI 개발과 실행에 드는 비용때문에 소수에게 권력이 집중되는 경향을 예측하여, 비영리기관이라는 업계의 이목을 집중시켜, 경쟁사와는 다른 출발한 것에 대해 실리콘밸리 사람들의 대단한 예측력과 사업추진력을 알수 있음
>
> 그리고 startup 기업이 초창기 목표와 비전을 지켜나가기 위해서 어떤 갈등이 있고, 어떻게 해쳐나가는지도 느껴질 수 있음
> 
> 어떻게 OpenAI와 같은 기업을 우리가 기대할 수 있을까? 가장 중요한 인력확보? 그리고 투자자? 
> 우리나라도 세계적인 경쟁력을 가진 기업들과 국가(정부)가 역할을 분담하여, AI에 대한 선택과 집중할 분야를 선정하여 투자할 필요가 있을 듯하다. 분명히 AI산업에서 우리가 들어갈 수 있는 틈새가 있을 것이며, 우리가 잘 하는 부분도 있을 것이기 때문이다. 
> 아니면 다양한 기업과 국가들 사이에서 기술력이 아니라 관계력을 발휘할 수도...
    
---
### OpenAI 

샌프란시스코 18번가와 폴섬 스트리트의 교차로에 위치한 OpenAI의 사무실

유서 깊은 이 건물은 칙칙한 회색 판넬과 틴티드 창문으로 이루어져 있으며 대부분의 블라인드가 내려져 있고, 
과거 소유주였던 파이오니어 트럭 팩토리의 흔적인 "PIONEER BUILDING"이라는 글자가 빛바랜 빨간색 페인트로 모퉁이를 감싸고 있음

내부는 밝고 통풍이 잘되는 공간. 1층에는 몇 개의 공용 공간과 두 개의 회의실. 

한 곳은 대규모 회의를 진행하기에 적당한 크기인 스페이스 오디세이, 다른 한 곳은 전화 부스처럼 꾸며진 인피니트 제스트라고 불립니다. 이곳은 제가 방문하는 동안 출입이 제한되는 공간입니다. 2층과 3층에는 모든 사람의 책상과 여러 대의 로봇, 그리고 거의 모든 흥미로운 물건이 있습니다. 인터뷰 시간이 되면 사람들이 저에게 내려옵니다. 한 직원이 회의 중간중간 저를 주시합니다.


<figure>
    <img src="https://cdn.technologyreview.com/i/images/pioneertrunkfactory-c-a-malmco-2012-09-0115-43-33-2.jpg?sw=700&cx=0&cy=0&cw=2560&ch=1838"
         alt="The Pioneer Building">
    <figcaption> <br> The Pioneer Building.</br> wikimedia commons / tfinc </figcaption>
</figure>


파란 하늘이 아름다운 날 브록먼을 만나러 도착한 날, 그는 긴장한 듯 경계하는 표정이었습니다. "이렇게 많은 액세스 권한을 부여한 적은 처음입니다."라고 그는 살짝 미소를 지으며 말합니다. 그는 캐주얼한 옷차림에 OpenAI의 다른 직원들과 마찬가지로 효율적이고 군더더기 없는 사고방식을 반영하는 듯 덥수룩한 헤어스타일을 하고 있습니다.

올해 31세인 브록먼은 노스다코타의 취미 농장에서 자랐으며, "집중력 있고 조용한 어린 시절"을 보냈다고 설명합니다. 소의 젖을 짜고, 달걀을 모으고, 독학으로 공부하면서 수학의 매력에 푹 빠졌습니다. 2008년 수학과 컴퓨터 공학을 복수 전공할 생각으로 하버드에 입학했지만, 현실 세계에 뛰어들기에는 금세 불안해졌습니다. 그는 1년 후 자퇴하고 대신 MIT에 입학했다가 몇 달 만에 다시 자퇴했습니다. 두 번째는 그의 결정이 최종적이었습니다. 샌프란시스코로 이사한 후 그는 뒤도 돌아보지 않았습니다.

브록먼은 회사 전체 회의가 열리는 동안 저를 사무실로 데려가 점심을 먹게 했습니다. 길 건너편 카페에서 그는 강렬하고 진지하게, 그리고 경이로움에 가득 찬 목소리로 OpenAI에 대해 이야기하면서 종종 그 사명과 과학사의 획기적인 업적 사이의 유사점을 이끌어 냈습니다. 리더로서 그의 카리스마를 쉽게 느낄 수 있습니다. 그는 자신이 읽은 책에서 기억에 남는 구절을 이야기하면서 밸리에서 가장 좋아하는 이야기인 미국의 달 탐사 경쟁에 대해 집중적으로 설명합니다. ("제가 정말 좋아하는 이야기 중 하나는 청소부 이야기입니다."라고 그는 유명하지만 아마도 위서일지도 모르는 이야기를 언급하며 말합니다. "케네디가 청소부에게 다가가 '뭐 하는 거냐'고 묻자 청소부는 '사람을 달에 보내는 일을 돕고 있습니다'라고 대답했습니다.") 또한 대륙 횡단 철도("실제로는 전적으로 수작업으로 이루어진 마지막 거대 프로젝트였고... 엄청난 규모의 프로젝트였기 때문에 완전히 위험했습니다.")와 토머스 에디슨의 백열전구("저명한 전문가들로 구성된 위원회가 '절대 성공할 수 없다'고 말했지만 1년 후 그는 출하했습니다.")도 있습니다.

<figure>
    <img src="https://cdn.technologyreview.com/i/images/cf3a2258final.jpg?sw=700&cx=133&cy=611&cw=1792&ch=2389"
         alt=" Greg Brockman">
    <figcaption> <br> Greg Brockman, co-founder and CTO.</br> Christie Hemm Klok / tfinc </figcaption>
</figure>

브록먼은 OpenAI가 얼마나 위험한 도박을 하고 있는지, 그리고 그것이 냉소주의와 의심의 눈초리를 불러일으킨다는 사실을 잘 알고 있습니다. 하지만 그가 전하는 메시지는 분명합니다. 사람들은 얼마든지 회의적일 수 있다는 것입니다. 대담한 도전의 대가입니다.

---
### OpenAI 등장 이후 최근까지


초창기 OpenAI에 합류한 사람들은 그 에너지와 흥분, 목적 의식을 기억합니다. 긴밀한 연결망을 통해 소규모로 구성된 팀이었으며, 경영진은 느슨하고 비공식적으로 운영되었습니다. 모두가 누구든 아이디어와 토론을 할 수 있는 평등한 구조를 믿었습니다.

집단적 신화를 구축하는 데 머스크의 역할도 적지 않았습니다. "그가 저에게 제시한 방식은 '이봐요, 알겠어요. 하지만 만약 그렇지 않다면?"이라는 식이었습니다." UC 버클리의 피터 애빌 교수는 처음 2년 동안 여러 학생들과 함께 그곳에서 일했다고 회상합니다. "'향후 5년에서 10년 내에 이런 일이 일어날 확률이 1% 또는 0.1%라도 된다면 어떨까요? 아주 신중하게 생각해야 하지 않을까요? 그 말에 공감이 갔습니다."라고 그는 말합니다.

하지만 이러한 비공식성은 방향성의 모호함으로 이어지기도 했습니다. 2016년 5월, 알트먼과 브록먼은 당시 Google 연구원이었던 다리오 아모데이의 방문을 받았는데, 아모데이는 아무도 자신들이 하는 일을 이해하지 못한다고 말했습니다. 뉴요커에 실린 기사에 따르면, 팀 자체도 이 사실을 잘 모르고 있었다고 합니다. 브록먼은 "지금 우리의 목표는... 최선을 다하는 것입니다."라고 말합니다. "조금 모호합니다."

그럼에도 불구하고 아모데이는 몇 달 후 팀에 합류했습니다. 그의 여동생인 다니엘라 아모데이는 이전에 브록맨과 함께 일한 적이 있었고, 이미 OpenAI의 많은 구성원을 알고 있었기 때문입니다. 2년 후, 브록먼의 요청으로 다니엘라도 합류했습니다. "우리가 아무것도 없이 시작했다고 상상해 보세요."라고 브록먼은 말합니다. "우리는 그저 AGI가 잘 되었으면 좋겠다는 이상만 가지고 있었습니다."

### Throughout our lunch, Brockman recites the charter like scripture, an explanation for every aspect of the company’s existence.

15개월이 지난 2017년 3월, 경영진은 이제 더 집중해야 할 때라는 것을 깨달았습니다. 그래서 브록맨과 몇몇 핵심 멤버들은 AGI로 가는 길을 제시하는 내부 문서 초안을 작성하기 시작했습니다. 하지만 이 과정에서 치명적인 결함이 금방 드러났습니다. 팀은 이 분야의 트렌드를 연구하면서 비영리 단체로 남는 것이 재정적으로 불가능하다는 사실을 깨달았습니다. 이 분야의 다른 사람들이 획기적인 결과를 얻기 위해 사용하는 컴퓨팅 리소스는 3.4개월마다 두 배씩 증가하고 있었습니다. 브록먼은 "관련성을 유지하려면" 이러한 기하급수적인 증가에 대응하거나 이를 뛰어넘을 수 있는 충분한 자본이 필요하다는 것이 분명해졌다고 말합니다. 그러기 위해서는 빠르게 자금을 모으는 동시에 미션에 충실할 수 있는 새로운 조직 모델이 필요했습니다.

일반 대중과 대부분의 직원들은 알지 못하지만, 2018년 4월에 OpenAI는 이를 염두에 두고 헌장을 발표했습니다. 이 문서에는 연구소의 핵심 가치를 다시 표현하되, 새로운 현실을 반영해 표현을 미묘하게 바꿨습니다. "인류를 해치거나 권력을 과도하게 집중시키는 AI 또는 AGI의 사용을 피한다"는 약속과 함께 자원의 필요성도 강조했습니다. "우리의 사명을 완수하기 위해 상당한 자원을 동원해야 할 것으로 예상한다"면서도 "광범위한 이익을 훼손할 수 있는 직원과 이해관계자 간의 이해 상충을 최소화하기 위해 항상 성실히 행동할 것"이라고 밝혔습니다.

브록먼은 "회사 전체가 일련의 원칙을 받아들이도록 하기 위해 내부적으로 직원들과 오랜 시간 반복적으로 논의했습니다."라고 말합니다. "회사의 구조가 바뀌어도 변하지 않아야 하는 것들이었습니다."

<figure>
    <img src="https://cdn.technologyreview.com/i/images/cf3a2221final.jpg?sw=700&cx=0&cy=0&cw=3000&ch=1688"
         alt=" From left to right">
    <figcaption> <br>From left to right: Daniela Amodei, Jack Clark, Dario Amodei, Jeff Wu (technical staff member), Greg Brockman, Alec Radford (technical language team lead), Christine Payne (technical staff member), Ilya Sutskever, and Chris Berner (head of infrastructure).</br> Christie Hemm Klok </figcaption>
</figure>


이러한 구조 변화는 2019년 3월에 이루어졌습니다. OpenAI는 비영리 단체의 일부인 이사회가 감독하긴 하지만 투자자의 수익을 100배로 제한하는 영리 법인인 '수익 상한제' 부서를 설립함으로써 순수 비영리 단체의 지위를 박탈했습니다. 얼마 지나지 않아 Microsoft가 10억 달러를 투자한다고 발표했습니다(이 금액이 현금과 Microsoft의 클라우드 컴퓨팅 플랫폼인 Azure에 대한 크레딧으로 나뉜다는 사실은 밝히지 않았습니다).

예상대로 이러한 움직임은 OpenAI가 본연의 임무에서 벗어나고 있다는 비난의 물결을 일으켰습니다. 발표 직후 Hacker News에 올라온 게시물에서 한 사용자는 100배 제한이 어떻게 제한이 될 수 있는지 물었습니다. "구글의 초기 투자자들은 자본금 대비 약 20배의 수익을 얻었습니다."라고 그들은 썼습니다. "구글보다 몇 배나 더 많은 수익을 내는 기업 구조를 갖게 될 텐데 '과도한 권력 집중'을 원하지 않는다고요? 어떻게 할 수 있을까요? 자원의 집중이 아니라면 권력이란 정확히 무엇일까요?"

이러한 움직임에 많은 직원들도 비슷한 우려를 표명했습니다. 내부의 불안을 잠재우기 위해 경영진은 철저한 보안이 보장된 일련의 전환 문서의 일부로 FAQ를 작성했습니다. "OpenAI를 믿어도 되나요?" 한 질문이 있었습니다. "예"라는 대답과 함께 설명이 이어졌습니다.


---

[헌장](https://openai.com/charter/)은 OpenAI의 근간입니다. 헌장은 연구소의 모든 전략과 행동의 발판 역할을 합니다. 점심 식사 내내 브록먼은 회사의 모든 측면을 설명하는 경전처럼 이 헌장을 낭독했습니다. (한 대사를 암송하는 도중에 그는 "그런데 이 모든 대사를 정확히 알아듣기 위해 많은 시간을 들여 꼼꼼히 살펴봤기 때문에 잘 알고 있는 것 같다"고 설명합니다. 회의 전에 이 글을 읽었던 것과는 전혀 달라요.")

> ***더 발전된 역량을 개발하는 과정에서 인간이 의미 있는 삶을 지속할 수 있도록 어떻게 보장할 것인가요?(How will you ensure that humans continue to live meaningful lives as you develop more advanced capabilities?)*** -> "모든 사람에게 경제적 자유를 주고, 현재로서는 상상할 수 없는 새로운 기회를 찾을 수 있도록 하는 것이 그 영향력이 되어야 한다고 생각합니다." 
> 
> ***AGI를 균등하게 분배하기 위해 어떻게 조직을 구성할 것인가요?(How will you structure yourself to evenly distribute AGI?)***  -> "유틸리티는 우리가 가진 비전을 가장 잘 비유한 것이라고 생각합니다. 하지만 이 모든 것은 헌장의 적용을 받습니다." 
> 
> ***안전을 저해하지 않으면서 AGI에 먼저 도달하기 위해 어떻게 경쟁하나요?(How do you compete to reach AGI first without compromising safety?)*** -> "균형을 잡는 것이 중요하다고 생각하며, 이를 위한 최선의 방법은 헌장에 명시된 것입니다."

Brockman에게 있어 문서에 대한 엄격한 준수는 OpenAI의 구조를 작동시키는 원동력입니다. 모든 정규직 직원은 몇 가지 예외를 제외하고는 같은 사무실에서 근무해야 할 정도로 내부 조율을 가장 중요하게 여깁니다. 정책팀, 특히 디렉터인 Jack Clark에게는 샌프란시스코와 워싱턴 DC를 오가는 생활이 필수적입니다. Clark은 이런 생활 방식에 전혀 개의치 않습니다. 그는 동료들과 함께 하는 점심시간과 같은 중간중간의 순간이 모두가 같은 생각을 공유할 수 있도록 도와준다고 말합니다.

여러 면에서 이 접근 방식은 분명히 효과가 있습니다. 이 회사는 인상적으로 획일적인 문화를 가지고 있습니다. 직원들은 장시간 근무하고 식사 및 사교 시간을 통해 업무에 대해 끊임없이 이야기하며, 많은 직원이 같은 파티에 참석하고 "효과적인 이타주의"라는 합리적 철학을 신봉합니다. 이들은 머신러닝 용어를 사용해 농담을 주고받으며 자신의 삶을 설명합니다: "당신의 삶은 무엇의 함수입니까?" "당신은 무엇을 위해 최적화하고 있나요?" "모든 것은 기본적으로 최소함수입니다." 공정하게 말하자면, 다른 AI 연구자들도 이런 일을 좋아하지만, OpenAI를 잘 아는 사람들은 이 분야의 다른 사람들보다 직원들이 AI 연구를 직업이 아니라 정체성으로 여긴다고 말합니다. (지난 11월, 브록먼은 1년 동안 사귄 여자친구 안나와 사무실에서 OpenAI 로고로 장식된 꽃을 배경으로 결혼식을 올렸습니다. 주례는 서츠케버가 맡았고, 반지를 든 로봇 손이 반지를 전달했습니다.)


하지만 작년 중반 어느 순간, 헌장은 점심시간의 대화 소재 이상의 의미를 갖게 되었습니다. 수익 상한제로 전환한 직후, 경영진은 부분적으로 각 직원의 사명 몰입도를 기준으로 새로운 급여 체계를 도입했습니다. '통합 기술 사다리'라는 제목의 스프레드시트 탭에 '엔지니어링 전문성', '연구 방향' 등의 열과 함께 마지막 열에는 각 직급에 대한 문화 관련 기대치가 요약되어 있습니다. 레벨 3: "OpenAI 헌장을 이해하고 내재화합니다." 레벨 5: "자신과 팀원이 참여하는 모든 프로젝트가 헌장에 부합하는지 확인합니다." 레벨 7: "헌장을 준수하고 개선하며, 조직 내 다른 사람에게도 동일한 책임을 부여할 책임이 있습니다."


대부분의 사람들이 OpenAI에 대해 처음 들어본 것은 2019년 2월 14일이었습니다. 그날 연구소는 버튼 하나만 누르면 설득력 있는 에세이와 기사를 생성할 수 있는 모델이라는 인상적인 새 연구를 발표했습니다. 반지의 제왕에 나오는 문장이나 마일리 사이러스의 절도 행각에 관한 (가짜) 뉴스의 첫 문장을 입력하면 같은 맥락의 텍스트를 여러 문단 이어서 뱉어내는 것이었습니다.

하지만 연구원들은 GPT-2라고 불리는 이 모델은 출시하기에는 너무 위험하다고 말했습니다. 이러한 강력한 기술이 악의적인 사람의 손에 들어가면 엄청난 규모의 허위 정보를 생산하기 위해 쉽게 무기화될 수 있습니다.

과학자들 사이에서는 즉각적인 반발이 일어났습니다. 일부 과학자들은 OpenAI가 홍보를 위한 쇼를 벌이고 있다고 말했습니다. GPT-2는 위협이 될 만큼 충분히 발전하지 않았다는 것이었습니다. 만약 위협이 된다면 왜 그 존재를 발표하고 대중의 조사를 막았을까? AI로 생성된 허위 정보를 연구하는 럿거스 대학교의 조교수인 브릿 패리스(Britt Paris)는 "OpenAI가 AI에 대한 공포를 이용하려는 것 같았다"고 말합니다.

<figure>
    <img src="https://cdn.technologyreview.com/i/images/cf3a2285final-web.jpg?sw=700&cx=30&cy=411&cw=1940&ch=2587"
         alt="Jack Clark">
    <figcaption> <br> Jack Clark, policy director.</br> Christie Hemm Klok </figcaption>
</figure>

5월이 되자 OpenAI는 입장을 수정하여 "단계적 출시" 계획을 발표했습니다. 그 후 몇 달에 걸쳐 점점 더 강력한 버전의 GPT-2를 순차적으로 출시했습니다. 그 사이에도 여러 연구 기관과 협력하여 알고리즘의 악용 가능성을 면밀히 조사하고 대응책을 개발했습니다. 마침내 11월에 전체 코드를 공개하면서 "아직까지 오용의 강력한 증거는 발견되지 않았다"고 밝혔습니다.

대중의 관심을 끌기 위한 것이라는 비난이 계속되는 가운데 OpenAI는 GPT-2가 스턴트가 아니라고 주장했습니다. 오히려 일련의 내부 논의와 토론을 거쳐 합의된 신중한 실험이었다고 주장했습니다. 이번에는 다소 과한 행동이었더라도 앞으로 더 위험한 연구를 처리하는 데 선례가 될 것이라는 데 의견이 일치했습니다. 게다가 헌장에서는 "안전과 보안 문제"로 인해 연구소가 "앞으로 전통적인 출판을 점차 줄여야 할 것"이라고 예측했습니다.

이는 제가 회의에 참석했을 때 정책팀이 6개월에 걸친 후속 블로그 게시물에서 신중하게 설명한 주장이기도 합니다. 정책 연구 과학자인 마일스 브런디지는 Google 문서에 있는 내용을 강조하며 "이것이 바로 성공 사례 프레임워크의 일부라고 생각합니다."라고 말했습니다. "이 섹션의 선두에 서야 합니다: "우리는 야심 찬 일을 해냈고, 이제 몇몇 사람들이 그것을 모방하고 있으며, 그것이 유익했던 몇 가지 이유가 있습니다."

그러나 GPT-2를 이용한 OpenAI의 미디어 캠페인은 광범위한 AI 커뮤니티를 불안하게 만드는 잘 정립된 패턴을 따르기도 했습니다. 지난 몇 년 동안 이 연구소의 크고 화려한 연구 발표는 AI 과대광고 주기를 부추긴다는 비난을 반복적으로 받아왔습니다. 또한 비평가들은 이 연구소가 연구 결과를 지나치게 부풀렸다는 비난을 여러 차례 받기도 했습니다. 이러한 이유로 이 분야의 많은 사람들은 OpenAI를 멀리하는 경향이 있습니다.

<figure>
    <img src="https://cdn.technologyreview.com/i/images/cf3a2404.jpg?sw=700&cx=0&cy=0&cw=3000&ch=2000"
         alt="OpenAI office wall">
    <figcaption> <br> Cover images of OpenAI's research releases hang on its office wall.</br> Christie Hemm Klok </figcaption>
</figure>

그렇다고 해서 연구소가 대외적인 이미지 제고에 지속적으로 자원을 투입하는 것을 멈추지 않았습니다. 연구 논문은 물론, 글쓰기부터 멀티미디어 제작, 표지 이미지 디자인까지 모든 것을 자체적으로 제작하는 회사 블로그 게시물을 통해 연구 결과를 발표하고 있습니다. 한때는 딥마인드의 알파고에 관한 90분짜리 영화에 버금가는 다큐멘터리를 제작하기 위해 프로젝트 중 하나에 대한 다큐멘터리 개발에 착수하기도 했습니다. 결국 이 작업은 독립 제작으로 이어졌고, 현재 브록맨과 그의 아내 Anna가 부분적으로 자금을 지원하고 있습니다. (저는 다큐멘터리에 출연하여 OpenAI의 성과에 대한 기술적 설명과 맥락을 제공하는 데 동의했습니다. 이에 대한 보상은 받지 않았습니다.)

반발이 커지면서 이를 해결하기 위한 내부 논의도 진행 중입니다. 직원들은 외부의 끊임없는 비판에 좌절감을 느꼈고, 경영진은 이로 인해 연구소의 영향력과 최고의 인재를 채용할 수 있는 능력이 약화될 것을 우려했습니다. 내부 문서에는 이 문제와 이를 해결하기 위한 홍보 전략이 나와 있습니다: "정부 차원의 정책적 영향력을 가지려면 ML[머신러닝] 연구와 AGI에 대해 가장 신뢰할 수 있는 출처로 여겨져야 합니다."라고 '정책' 섹션의 한 줄에 적혀 있습니다. "연구 커뮤니티의 광범위한 지원과 지지는 그러한 평판을 얻는 데 필요할 뿐만 아니라 우리의 메시지를 증폭시킬 것입니다." 또 다른 항목은 '전략' 아래에 "ML 커뮤니티를 커뮤니케이션 이해관계자로 명시적으로 취급합니다. 우리가 의도적으로 선택한 경우에만 커뮤니티를 적대시하도록 어조와 외부 메시지를 변경합니다."


---

GPT-2가 그토록 격렬한 반발을 불러일으킨 데에는 또 다른 이유가 있었습니다. 사람들은 OpenAI가 개방성과 투명성에 대한 초기의 약속을 다시 한 번 후퇴하고 있다고 느꼈습니다. 한 달 후 영리 전환 소식이 전해지면서 연구 보류 소식은 사람들을 더욱 의심하게 만들었습니다. 혹시 향후 라이선스를 취득하기 위해 이 기술을 비밀에 부친 것은 아닐까요?



<figure>
    <img src="https://cdn.technologyreview.com/i/images/cf3a2366final.jpg?sw=700&cx=0&cy=223&cw=1333&ch=1777"
         alt="Ilya Sutskever">
    <figcaption> <br>Ilya Sutskever, co-founder and chief scientist. </br> Christie Hemm Klok </figcaption>
</figure>

---
하지만 OpenAI가 연구 결과를 숨긴 것이 이번만이 아니라는 사실을 아는 사람은 거의 없었습니다. 사실 오픈AI는 또 다른 연구를 완전히 비밀에 부쳤습니다.

AGI에 도달하기 위해 무엇이 필요한지에 대한 두 가지 기술 이론이 널리 퍼져 있습니다. 하나는 필요한 모든 기술이 이미 존재하며, 이를 어떻게 확장하고 조립할지 알아내는 것만 남았다는 이론입니다. 다른 하나는 완전히 새로운 패러다임이 필요하다는 것인데, 현재 AI의 지배적인 기술인 딥러닝만으로는 충분하지 않다는 것입니다.

대부분의 연구자들은 이 두 가지 극단적인 입장 중 어느 쪽에 속하지만, OpenAI는 거의 독점적으로 확장 및 조립 쪽에 속해 있습니다. 대부분의 혁신은 다른 연구실에서 개발된 기술 혁신에 훨씬 더 많은 컴퓨팅 리소스를 투입한 결과였습니다.

브록맨과 서츠케버는 이것이 자신들의 유일한 전략이라고 부인하지만, 연구소의 철저한 보안을 유지하고 있는 연구 결과는 그렇지 않다는 것을 시사합니다. '포사이트'라는 팀은 점점 더 많은 양의 데이터와 컴퓨팅 성능으로 기존 알고리즘을 훈련시켜 AI 기능을 어디까지 발전시킬 수 있는지 테스트하는 실험을 진행합니다. 경영진은 이러한 실험의 결과를 통해 연구소의 컴퓨팅 중심 전략이 최선의 접근 방식이라는 본능을 확인했습니다.

약 6개월 동안 이러한 결과는 외부에 공개되지 않았는데, OpenAI는 이러한 지식이 자사의 주요 경쟁 우위라고 생각했기 때문입니다. 직원과 인턴에게 공개하지 말라고 명시적으로 지시했고, 퇴사한 직원들은 기밀유지 계약서에 서명했습니다. 지난 1월이 되어서야 이 팀은 일반적인 팡파르 없이 조용히 AI 연구를 위한 주요 오픈소스 데이터베이스 중 하나에 논문을 게시했습니다. 이 연구와 관련된 극도의 비밀주의를 경험한 사람들은 이 변화를 어떻게 받아들여야 할지 몰랐습니다. 특히, 몇 달 전에 다른 연구자들이 비슷한 결과를 담은 또 다른 논문이 게시된 적이 있었습니다.


---

처음에는 이러한 수준의 비밀 유지가 의도된 바는 아니었지만, 이후 습관화되었습니다. 시간이 지남에 따라 리더십은 개방성이 유익한 AGI를 구축하는 가장 좋은 방법이라는 원래의 믿음에서 멀어졌습니다. 이제 침묵의 중요성은 연구소에서 함께 일하거나 연구소에서 일하는 사람들에게 깊은 인상을 남겼습니다. 여기에는 커뮤니케이션 팀의 명시적인 허가 없이는 기자에게 절대로 말하지 않는 것도 포함됩니다. 처음 사무실을 방문한 후 다른 직원들과 연락을 취하기 시작했을 때 커뮤니케이션 책임자로부터 모든 인터뷰 요청은 자신을 거쳐야 한다는 이메일을 받았습니다. 제가 사람들이 저에게 하는 말의 신빙성을 떨어뜨릴 수 있다며 거절하자, 그녀는 직원들에게 제가 연락을 취하면 계속 알려주라고 지시했습니다. 기자 출신인 클라크는 나중에 Slack 메시지를 통해 기자가 "주변을 기웃거리고 있다"며 직원들을 칭찬했습니다.

이러한 비밀주의 강화에 대한 성명에서 OpenAI 대변인은 회사 헌장의 한 부분을 다시 언급했습니다. "우리는 안전과 보안 문제로 인해 앞으로 전통적인 출판이 줄어들 것으로 예상한다"며 "안전, 정책 및 표준 연구 공유의 중요성은 더욱 커질 것"이라고 밝혔습니다. 또한 대변인은 "또한 각 릴리스는 이러한 장단점을 평가하기 위해 정보 위험 프로세스를 거치고 있으며, 야생에 출시하기 전에 잠재적인 위험과 영향을 파악하기 위해 결과를 천천히 공개하고자 합니다."라고 덧붙였습니다.

가장 큰 비밀 중 하나는 OpenAI가 다음에 진행 중인 프로젝트입니다. 소식통에 따르면 이 프로젝트는 지난 4년간의 연구의 정점으로, 대규모 컴퓨팅 리소스를 사용해 이미지, 텍스트 및 기타 데이터를 학습하는 AI 시스템이라고 설명했습니다. 초기 작업에는 소규모 팀이 배정되었으며, 다른 팀들도 이 작업에 동참할 것으로 예상됩니다. 이 계획이 전사 회의에서 발표되던 날, 인턴들은 회의에 참석할 수 없었습니다. 이 계획에 대해 잘 아는 사람들은 다음과 같이 설명합니다. 경영진은 이것이 AGI를 달성할 수 있는 가장 유망한 방법이라고 생각합니다.


