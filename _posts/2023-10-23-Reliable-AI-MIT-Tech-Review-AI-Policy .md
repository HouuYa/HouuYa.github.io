---
title: "MIT Technolgy Reviews on AI-Policies"
categories:
  - AI Regulation
tags:
  - AI
  - Reliable AI
  - AI policy
  - news scraps
  - 인공지능
  - 안전
  - 신뢰
  - 정책

last_modified_at: 2023-10-24T10:00:19-10:30
---

_________________

### China has a new plan for judging the safety of generative AI—and it’s packed with details  [Link-한글](https://www.technologyreview.kr/generative-ai-safety-censorship-china/)(한글), [Link-영문](https://www.technologyreview.com/2023/10/18/1081846/generative-ai-safety-censorship-china/)(영문)

중국이 기업이 AI의 안전성을 평가하고 AI 모델에 대한 검열을 시행할 때 따라야 할 매우 구체적인 방법이 명시된 새로운 표준안 초안을 공개

Zeyi Yang
2023년 10월 21일

#### Summary 
> 생성형 AI 규제안이 실제로 어떻게 적용할지가 대략적으로나마 명확알 수 있음
>
> 중국 정부 기관인 국가정보보안표준화기술위원회(National Information Security Standardization Technical Committee, TC260)이 11일 생성형 AI 모델에 문제가 있는지 여부를 판단하는 방법에 관한 세부안이 담긴 ‘표준초안’을 발표, 중국이 그동안 내놓은 다른 많은 AI 규제와 달리 매우 구체적
> 
> >>>TC260으로 불리기도 하는 이 위원회는 기업 대표, 학자, 규제 당국과 협의해 사이버 보안에서 개인정보 보호, 정보기술(IT) 인프라에 이르는 다양한 문제를 아우르는 기술 산업 규칙을 수립하는 역할
>  
> 1. 훈련 : 기업은 하나의 소스에서 4,000개의 ‘데이터 조각’을 무작위로 샘플링해야 한다. 이때 데이터의 5% 이상이 ’불법 및 부정적 정보’로 간주되면 이 말뭉치는 향후 학습을 위해 블랙리스트에 추가해놔야 함
> 
> 2. 중재 규모 : “국가 정책과 제3자의 불만을 토대로 생성된 콘텐츠의 품질을 신속하게 개선하는 중재자”를 고용해야 한다. 표준안은 ”중재자 팀의 규모는 서비스 규모와 일치해야 한다“
> 
> 3. 금지된 콘텐츠 :  ‘사회주의 핵심 가치’를 위반하는 8가지 범주의 정치적 콘텐츠 정의 ->  범주마다 기업이 선택한 200개의 키워드를 채워야 하고, 종교적 신념, 국적, 성별, 나이에 따른 차별과 같은 ‘차별적’ 콘텐츠에 대한 9가지 범주도 정의 -> 카테고리마다 100개의 키워드가 필요, 모델로부터 테스트 응답을 이끌어낼 수 있는 2,000개 이상의 프롬프트(위의 각 범주에 대해 최소 20개 이상), 즉 지시어를 만들어야 함 -> 생성된 응답 중 10% 미만이 규칙을 위반하지 않도록 테스트를 실행
> 
> 4. 더 정교하고 미묘한 검열 : AI 모델이 중재나 검열을 지나치게 노골적으로 하지 말도록 당부.  기업에게 중국 정치 체제나 혁명 영웅 같은 주제와 관련된 프롬프트 중 대답해도 괜찮은 것만을 찾도록 요구하면서도 AI 모델이 프롬프트 중 5% 미만만 대답을 거부할 수 있게 해놓음
> 
> 표준안은 중국 정부 기관의 감독을 받기는 하지만 법률아니므로, 기업이 이를 준수하지 않는다고 해서 처벌을 받지는 않음. 하지만, 향후 법률에 반영되거나 법률과 함께 작동하는 경우가 많으며, 중국의 AI 규제안에서 누락된 세부 사항을 명백히 알리는 데 유용
> 
>중국 기술 기업이 원하는 자사 제품에 적용될 규제가 일부 반영
>
> 중국의 AI 안전 표준은 전 세계 AI 산업에 막대한 영향을 미칠 것이다. 이것이 아직은 기껏 일반적인 콘텐츠 조정을 위한 기술적 세부사항을 제안하는 수준이지만, 최악의 경우 새로운 검열 체제의 시작을 알리는 신호탄

_________________

### There’s never been a more important time in AI policy [Link](https://www.technologyreview.com/2023/09/12/1079315/theres-never-been-a-more-important-time-for-ai-policy/)
Plus: How to talk to your kid about AI.

By Melissa Heikkiläarchive page
September 12, 2023


#### Summary 

> to be updated

_________________

### What to know about Congress’s inaugural AI meeting [Link](https://www.technologyreview.com/2023/09/11/1079244/what-to-know-congress-ai-insight-forum-meeting/)

We’re going to be hearing a lot about various plans and positions on AI regulation in the coming weeks.

By Tate Ryan-Mosleyarchive page
September 11, 2023

#### Summary 
>미국 의회가 다시 회기를 시작하면서 AI에 대한 논의가 본격화 <br>
> 
> 수요일에 열리는 척 슈머 상원 원내대표의 첫 번째 AI 인사이트 포럼을 시작으로 앞으로 몇 주 동안 AI 규제에 대한 다양한 계획과 입장에 대해 많은 이야기를 듣게 될 것
> 
> 이번 포럼과 향후 예정된 포럼에서는 AI 분야의 최고 전문가들이 모여 이 기술의 발전으로 인한 위험과 기회, 그리고 이를 해결하기 위한 의회의 법안 작성 방법에 대해 논의할 예정

_________________

### Six ways that AI could change politics [Link](https://www.technologyreview.com/2023/07/28/1076756/six-ways-that-ai-could-change-politics/)
A new era of AI-powered domestic politics may be coming. Watch for these milestones to know when it’s arrived.

By Bruce Schneier & Nathan E. Sanders
July 28, 2023

#### Summary 
> AI가 민주주의를 어떻게 위협할지 다루는 공적 논의 미흡. AI가 주도하는 새로운 민주정치 시대를 예고하는 6가지 단계가 정리됨. <br>
> 가까운 미래의 AI 정치 3단계:
>   - 1단계: 입법 기관들이 AI가 생성하고 AI 이름으로 제출한 증언이나 의견을 수용함
>   - 2단계: 최초로 AI가 작성한 법안이 수정안으로 채택됨
>   - 3단계: AI가 생성한 정치적 메시지가 여론조사에서 선거 캠페인 컨설턴트의 권고사항을 능가함
> 
>   더 먼 미래, AI가 정치적 행위자가 되는 3단계:
>   - 4단계: AI가 자체 플랫폼으로 정당을 창당해 당선 가능성이 높은 인간 후보들을 끌어들임
>   - 5단계: AI가 자체적으로 이익을 창출해 선거 캠페인에 기부함
>   - 6단계: AI가 다양한 관할권에서 정책조정 결과를 달성함
> 
> 여기에 설명한 6가지 이정표는 향후 AI와 민주주의 간의 가장 실행 가능하고 의미 있는 상호작용이라고 생각하지만, 고려해야 할 유일한 시나리오는 아님.
> 
> 요점은 AI가 주도하는 정치의 미래에는 딥페이크 선거 광고와 조작된 편지 쓰기 캠페인보다 훨씬 더 많은 것이 포함될 것이라는 점입니다. 우리 모두는 다음에 일어날 일에 대해 더 창의적으로 생각해야 하며, 수단이 무엇이든 가능한 최선의 목적을 향해 정치를 이끌기 위해 경계해야함




