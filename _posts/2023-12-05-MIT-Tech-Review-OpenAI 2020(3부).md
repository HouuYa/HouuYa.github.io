---
title: "[MIT Technolgy Reviews] The messy, secretive reality behind OpenAI’s bid to save the world (3부)"
categories:
  - AI Company
tags:
  - OpenAI
  - Greg Brockman
  - 그렉 브록만
  - AI
  - MIT Technolgy Reviews
# - Reliable AI
#  - AI policy
#  - news scraps
  - 인공지능
#  - 안전
#  - 신뢰
#  - 정책

last_modified_at: 2023-12-07T10:30:11-11:10
---
_________________

ARTIFICIAL INTELLIGENCE

# The messy, secretive reality behind OpenAI’s bid to save the world(3/5)

#### The AI moonshot was founded in the spirit of transparency. This is the inside story of how competitive pressure eroded that idealism.

##### By Karen Hao
##### February 17, 2020
---


  * MIT Technolgy Reviews에 2020년 2월 17일, AI분야 기자 [Karen Hao](https://www.technologyreview.com/author/karen-hao/)이 작성한 [기사](https://www.technologyreview.com/2020/02/17/844721/ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality/)를 DeepL로 번역 후, "포괄적 요약"하고, "저의 의견"을 추가하여 작성한 내용
  * 아주 긴 기사를 나름 5부로 나누어 OpenAI에 대해서 공부할 겸 정리해보았음
  * 2022년 ChatGPT로 일반인들(나 포함)에게 알려지기 까지, 2019년 2020년 초에 OpenAI가 어떤 기업이였는지 알 수 있는 자료
  * 만약 저작권에 문제가 있다면 바로 알려주세요!!

---

### OpenAI 헌장(The Charter), 조직 문화 그리고 임급체계

[헌장(The charter)](https://openai.com/charter/)은 OpenAI의 근간. 헌장은 연구소의 모든 전략과 행동의 발판 역할. 점심 식사 내내 브록먼은 회사의 존재에 대한 모든 측면들을 설명하는 경전처럼 이 헌장을 낭독. (한 대사를 암송하는 도중에 그는 "그런데 이 모든 대사를 정확히 알아듣기 위해 많은 시간을 들여 꼼꼼히 살펴봤기 때문에 잘 알고 있는 것 같이지 회의 전에 이 글을 읽었던 것과는 전혀 달라요."라고 말함)

> ***더 발전된 역량을 개발하면서, 당신은 인간이 의미 있는 삶을 지속할 수 있도록 어떻게 보장할 것인가요?(How will you ensure that humans continue to live meaningful lives as you develop more advanced capabilities?)*** -> "우리는 글을 작성한 것처럼, 모든 사람에게 경제적 자유를 주고, 현재로서는 상상할 수 없는 새로운 기회를 찾을 수 있도록 하는 것이 그 영향력이 되어야 한다고 생각합니다." 
> 
> ***AGI를 균등하게 분배하기 위해 어떻게 조직을 구성할 것인가요?(How will you structure yourself to evenly distribute AGI?)***  -> "저는 유틸리티는 우리가 가진 비전을 가장 잘 비유한 것이라고 생각합니다. 하지만 다시말하지만, 이 모든 것은 헌장의 적용을 받습니다." 
> 
> ***안전을 저해하지 않으면서 AGI에 먼저 도달하기 위해 어떻게 경쟁하나요?(How do you compete to reach AGI first without compromising safety?)*** -> "저는 균형을 잡는 것이 중요하다고 생각하며, 이를 위한 최선의 방법은 헌장에 명시된 것입니다."

Brockman에게 있어 문서에 대한 엄격한 준수는 OpenAI의 구조를 작동시키는 원동력. 모든 정규직 직원은 몇 가지 예외를 제외하고는 같은 사무실에서 근무해야 할 정도로 내부 조율(internal alignment)을 가장 중요하게 여김. 정책팀, 특히 디렉터인 Jack Clark에게는 샌프란시스코와 워싱턴 DC를 오가는 생활이 필수적. Clark은 이런 생활 방식에 전혀 개의치 않음. 그는 동료들과 함께 하는 점심시간과 같은 중간중간의 순간(in-between momnets)이 모두가 같은 생각을 공유할 수 있도록 도와준다고 말함.

여러 면에서 이 접근 방식은 분명히 효과가 있음: 이 회사는 인상적으로 획일적인 문화를 가지고 있음. 직원들은 장시간 근무하고 식사 및 사교 시간을 통해 업무에 대해 끊임없이 이야기하며, 많은 직원이 같은 파티에 참석하고 "효과적인 이타주의(effective altruism)"라는 합리적 철학을 신봉. 이들은 머신러닝 용어를 사용해 농담을 주고받으며 자신의 삶을 설명합니다: "당신의 삶은 무엇의 함수입니까(What is your life a function of)?" "당신은 무엇을 위해 최적화하고 있나요(What are you optimizing for)?" "모든 것은 기본적으로 최소함수입니다(Everything is basically a minmax function[^1])." 

공정하게 말하자면, 다른 AI 연구자들도 이런 일을 좋아하지만, OpenAI를 잘 아는 사람들은 이 분야의 다른 사람들보다 OpenAI 직원들은 AI 연구를 직업이 아니라 정체성으로 여긴다고 말함. (지난 11월, 브록먼은 1년 동안 사귄 여자친구 안나와 사무실에서 OpenAI 로고로 장식된 꽃을 배경으로 결혼식을 올렸음. 주례는 서츠케버가 맡았고, 반지를 든 로봇 손이 반지를 전달.)

 [^1]: 최소극대화(영어: Maximin) 또는 미니맥스는 결정이론, 게임이론, 통계학, 철학에서 사용하는 개념으로 최악의 경우 발생가능한 손실(최대 손실)을 최소화 한다는 규칙이다. 손실이 아니라 이익이 기준이라면 최소 이익을 극대화한다는 의미에서 "maximin" 이라고 부르기도 한다. 원래 두 명의 참가자가 존재하는 제로섬 게임 이론으로부터 시작하였으나 (두 참가자가 순차적으로 행동하는 경우와 동시에 행동하는 경우 모두 포함), 더 복잡한 게임과 불확실성이 존재할 때의 일반적인 의사결정에 이르기까지 널리 쓰이고 있다 from 위키백과


하지만 작년 중반 어느 순간, 헌장은 점심시간의 대화 소재 이상의 의미를 갖게 되었습니다. 수익 상한제로 전환한 직후, 경영진은 부분적으로 각 직원의 사명 몰입도(absortion)를 기준으로 새로운 급여 체계를 도입했음. '통합 기술 사다리(Unified Technical Ladder,)'라는 제목의 스프레드시트 탭에 '엔지니어링 전문성', '연구 방향' 등의 열과 함께 마지막 열에는 각 레벨(직급)에 대한 문화 관련 기대치가 요약:
    레벨 3: "당신은 OpenAI 헌장을 이해하고 내재화한다." 
    레벨 5: "당신은 자신과 팀원이 참여하는 모든 프로젝트가 헌장에 부합하도록 보장한다." 
    레벨 7: "당신은 헌장을 준수하고 개선하며, 다른 사람들도 동일한 행동할 수 있도록 책임을 부여할 책임이 있다."


### 2019년 2월, 대중에서 알려지기 시작한 계기가 된 'GPT 2.0 모델'의 출시, 그리고 외부의 비판

대부분의 사람들이 OpenAI에 대해 처음 들어본 것은 2019년 2월 14일. 그날 연구소는 버튼 하나만 누르면 설득력 있는 에세이와 기사를 생성할 수 있는 모델이라는 인상적인 새 연구를 발표. 반지의 제왕에 나오는 문장이나 마일리 사이러스의 절도 행각에 관한 (가짜) 뉴스의 첫 문장을 입력하면, 텍스트 문단 다음에 같은 맥락으로 단락을 이어서 뱉어냄

하지만 연구원들은 GPT-2라고 불리는 이 모델은 출시하기에는 너무 위험하다고 말하는 문제가 있었음. 이러한 강력한 기술이 악의적인 사람의 손에 들어가면 엄청난 규모로 허위 정보를 생산할 수 있도록 쉽게 무기화될 수 있었음.

과학자들 사이에서는 즉각적인 반발이 일어났음. 일부 과학자들은 OpenAI가 홍보를 위한 쇼(stunt, 이목을 끄는 행동)를 벌이고 있다고 말함. GPT-2는 위협이 될 만큼 충분히 발전하지 않았음. 만약 위협이 된다면 왜 그 존재를 발표하고 대중의 조사를 막았을까? AI로 생성된 허위 정보를 연구하는 럿거스 대학교의 조교수인 브릿 패리스(Britt Paris)는 "OpenAI가 AI에 대한 공포를 이용하려는(capitalize) 것 같았다"고 말함

<figure>
    <img src="https://cdn.technologyreview.com/i/images/cf3a2285final-web.jpg?sw=700&cx=30&cy=411&cw=1940&ch=2587"
         alt="Jack Clark">
    <figcaption> <br> Jack Clark, policy director.</br> Christie Hemm Klok </figcaption>
</figure>

5월이 되자 OpenAI는 입장을 수정하여 "단계적 출시" 계획을 발표. 그 후 몇 달에 걸쳐 점점 더 강력한 버전의 GPT-2를 순차적으로 출시. 그 사이에도 여러 연구 기관과 협력하여 알고리즘의 악용 가능성을 면밀히 조사하고 대응책을 개발. 마침내 11월에 전체 코드를 공개하면서 "아직까지 오용의 강력한 증거는 발견되지 않았다"고 밝힘

대중의 관심을 끌기 위한 것이라는 비난이 계속되는 가운데, 일부 사람들은 OpenAI는 GPT-2가 쇼(스턴트, 이목을 끄는 행동)가 아니라고 주장. 오히려 일련의 내부 논의와 토론을 거쳐 합의된 신중한 실험이었다고 주장. 이번에는 다소 과잉 행동(overkill)이었더라도, 앞으로 더 위험한 연구를 처리하는 데 선례가 될 것이라는 데 의견이 일치. 게다가 헌장은 "안전과 보안 문제"는 연구소가 "앞으로 전통적인 출판을 앞으로 줄이지 않을 수 없게 할 것"이라고 예측했었던 것.

이는 제가 회의에 참석했을 때 정책팀이 6개월에 걸친 후속 블로그 게시물에서 신중하게 설명한 주장이기도 함. 정책 연구 과학자인 마일스 브런디지는 Google 문서에 있는 어떤 내용을 강조하며 "이것이 바로 성공 사례 프레임워크의 일부라고 생각합니다."라고 말함. "이 섹션의 선두에 서야 합니다: "우리는 야심 찬 일을 해냈고, 이제 몇몇 사람들이 그것을 모방하고 있으며, 그것이 왜 유익했는지에 대한 몇 가지 이유가 있습니다."

그러나 GPT-2를 이용한 OpenAI의 미디어 캠페인은 광범위한 AI 커뮤니티를 불안하게(leery, 의심이 많게) 만드는 잘 정립된 패턴을 따르기도 했음. 지난 몇 년 동안 이 연구소의 크고 화려한 연구 발표는 AI 과대광고 주기를 부추긴다는 비난을 반복적으로 받아오고 있음. 또한 비평가들은 이 연구소가 연구 결과를 지나치게 부풀렸다는 비난을 여러 차례 받기도 했습니다. 이러한 이유로 이 분야의 많은 사람들은 OpenAI를 어느 정도 거리를 두려는(at arm’s length) 경향이 있었음

<figure>
    <img src="https://cdn.technologyreview.com/i/images/cf3a2404.jpg?sw=700&cx=0&cy=0&cw=3000&ch=2000"
         alt="OpenAI office wall">
    <figcaption> <br> Cover images of OpenAI's research releases hang on its office wall.</br> Christie Hemm Klok </figcaption>
</figure>


### 외부 비판/역풍에 대한 대응전략(공공 홍보 및 정부차원의 정책적 영향력 유지)

연구소는 대외적인 이미지에 대한 지속적으로 자원을 투입하는 것을 멈추지 않고 있음. 연구 논문은 물론, 
고도로 생산된 회사 블로그 게시물에 결과물을 게시하는데, 그 게시물을 위해서는 멀티미디어 제작을 위한 집필부터 각 릴리스의 표지 이미지 디자인까지 모든 작업을 사내에서 수행. 한때는 딥마인드의 알파고에 관한 90분짜리 영화에 버금가는 다큐멘터리를 제작하기 위해 프로젝트 중 하나에 대한 다큐멘터리 개발에 착수하기도 했음. 결국 이 노력은 독립적인 프로덕션으로 발전했으며, 현재 브록맨과 그의 아내 Anna가 부분적으로 자금을 지원하고 있음. (저는 다큐멘터리에 출연하여 OpenAI의 성과에 대한 기술적 설명과 맥락을 제공하는 데 동의으며, 이 기사에 대한 보상은 아니였음)

> > 현재까지도 OpenAI가 가지고 있는 조직 비전, 문화 그리고 다른 AI경쟁자들과의 차별성(대중 홍보 포함)이 왜 형성되었는지 왜 지금까지 유지하고 있는지를 알 수 있음

반발(역풍, blowback)이 커지면서, 이를 해결하기 위한 내부 논의도 진행 해야 했음. 직원들은 외부의 끊임없는 비판에 좌절감을 느꼈고, 경영진은 이로 인해 연구소의 영향력과 최고의 인재를 채용할 수 있는 능력이 약화될 것을 우려, 내부 문서에는 이 문제와 이를 해결하기 위한 아웃리치 전략(outreach strategy [^2])을 강조하고 있음: "정부 차원의 정책적 영향력을 가지려면 ML[머신러닝] 연구와 AGI에 대해 가장 신뢰할 수 있는 출처(source)로 여겨져야 합니다."라고 '정책' 섹션의 한 줄에 적혀 있음. "연구 커뮤니티의 광범위한 지원과 지지는 그러한 평판을 얻는 데 필요할 뿐만 아니라 우리의 메시지를 증폭시킬 것입니다." 또 다른 항목은 '전략' 아래에 "ML 커뮤니티를 커뮤니케이션 이해관계자로 명시적으로 취급합니다. 우리가 의도적으로 선택한 경우에만 커뮤니티를 적대시하도록 어조와 외부 메시지를 변경합니다."

   [^2] 도움과 충고가 필요한 사람들을 직접 찾아나서는 행위, 손길이 뻗치는 행동 또는 사실"은 reach out이라는  동사구에서 유래
   
---

### GPT-2에 대한 업계의 격렬한 반발 이유

<!-- GPT-2가 그토록 격렬한 반발을 불러일으킨 데에는 또 다른 이유가 있었습니다. 사람들은 OpenAI가 개방성과 투명성에 대한 초기의 약속을 다시 한 번 후퇴하고 있다고 느꼈습니다. 한 달 후 영리 전환 소식이 전해지면서 연구 보류 소식은 사람들을 더욱 의심하게 만들었습니다. 혹시 향후 라이선스를 취득하기 위해 이 기술을 비밀에 부친 것은 아닐까요?



<figure>
    <img src="https://cdn.technologyreview.com/i/images/cf3a2366final.jpg?sw=700&cx=0&cy=223&cw=1333&ch=1777"
         alt="Ilya Sutskever">
    <figcaption> <br>Ilya Sutskever, co-founder and chief scientist. </br> Christie Hemm Klok </figcaption>
</figure>

---
하지만 OpenAI가 연구 결과를 숨긴 것이 이번만이 아니라는 사실을 아는 사람은 거의 없었습니다. 사실 오픈AI는 또 다른 연구를 완전히 비밀에 부쳤습니다.

AGI에 도달하기 위해 무엇이 필요한지에 대한 두 가지 기술 이론이 널리 퍼져 있습니다. 하나는 필요한 모든 기술이 이미 존재하며, 이를 어떻게 확장하고 조립할지 알아내는 것만 남았다는 이론입니다. 다른 하나는 완전히 새로운 패러다임이 필요하다는 것인데, 현재 AI의 지배적인 기술인 딥러닝만으로는 충분하지 않다는 것입니다.

대부분의 연구자들은 이 두 가지 극단적인 입장 중 어느 쪽에 속하지만, OpenAI는 거의 독점적으로 확장 및 조립 쪽에 속해 있습니다. 대부분의 혁신은 다른 연구실에서 개발된 기술 혁신에 훨씬 더 많은 컴퓨팅 리소스를 투입한 결과였습니다.

브록맨과 서츠케버는 이것이 자신들의 유일한 전략이라고 부인하지만, 연구소의 철저한 보안을 유지하고 있는 연구 결과는 그렇지 않다는 것을 시사합니다. '포사이트'라는 팀은 점점 더 많은 양의 데이터와 컴퓨팅 성능으로 기존 알고리즘을 훈련시켜 AI 기능을 어디까지 발전시킬 수 있는지 테스트하는 실험을 진행합니다. 경영진은 이러한 실험의 결과를 통해 연구소의 컴퓨팅 중심 전략이 최선의 접근 방식이라는 본능을 확인했습니다.

약 6개월 동안 이러한 결과는 외부에 공개되지 않았는데, OpenAI는 이러한 지식이 자사의 주요 경쟁 우위라고 생각했기 때문입니다. 직원과 인턴에게 공개하지 말라고 명시적으로 지시했고, 퇴사한 직원들은 기밀유지 계약서에 서명했습니다. 지난 1월이 되어서야 이 팀은 일반적인 팡파르 없이 조용히 AI 연구를 위한 주요 오픈소스 데이터베이스 중 하나에 논문을 게시했습니다. 이 연구와 관련된 극도의 비밀주의를 경험한 사람들은 이 변화를 어떻게 받아들여야 할지 몰랐습니다. 특히, 몇 달 전에 다른 연구자들이 비슷한 결과를 담은 또 다른 논문이 게시된 적이 있었습니다.


---

처음에는 이러한 수준의 비밀 유지가 의도된 바는 아니었지만, 이후 습관화되었습니다. 시간이 지남에 따라 리더십은 개방성이 유익한 AGI를 구축하는 가장 좋은 방법이라는 원래의 믿음에서 멀어졌습니다. 이제 침묵의 중요성은 연구소에서 함께 일하거나 연구소에서 일하는 사람들에게 깊은 인상을 남겼습니다. 여기에는 커뮤니케이션 팀의 명시적인 허가 없이는 기자에게 절대로 말하지 않는 것도 포함됩니다. 처음 사무실을 방문한 후 다른 직원들과 연락을 취하기 시작했을 때 커뮤니케이션 책임자로부터 모든 인터뷰 요청은 자신을 거쳐야 한다는 이메일을 받았습니다. 제가 사람들이 저에게 하는 말의 신빙성을 떨어뜨릴 수 있다며 거절하자, 그녀는 직원들에게 제가 연락을 취하면 계속 알려주라고 지시했습니다. 기자 출신인 클라크는 나중에 Slack 메시지를 통해 기자가 "주변을 기웃거리고 있다"며 직원들을 칭찬했습니다.

이러한 비밀주의 강화에 대한 성명에서 OpenAI 대변인은 회사 헌장의 한 부분을 다시 언급했습니다. "우리는 안전과 보안 문제로 인해 앞으로 전통적인 출판이 줄어들 것으로 예상한다"며 "안전, 정책 및 표준 연구 공유의 중요성은 더욱 커질 것"이라고 밝혔습니다. 또한 대변인은 "또한 각 릴리스는 이러한 장단점을 평가하기 위해 정보 위험 프로세스를 거치고 있으며, 야생에 출시하기 전에 잠재적인 위험과 영향을 파악하기 위해 결과를 천천히 공개하고자 합니다."라고 덧붙였습니다.

가장 큰 비밀 중 하나는 OpenAI가 다음에 진행 중인 프로젝트입니다. 소식통에 따르면 이 프로젝트는 지난 4년간의 연구의 정점으로, 대규모 컴퓨팅 리소스를 사용해 이미지, 텍스트 및 기타 데이터를 학습하는 AI 시스템이라고 설명했습니다. 초기 작업에는 소규모 팀이 배정되었으며, 다른 팀들도 이 작업에 동참할 것으로 예상됩니다. 이 계획이 전사 회의에서 발표되던 날, 인턴들은 회의에 참석할 수 없었습니다. 이 계획에 대해 잘 아는 사람들은 다음과 같이 설명합니다. 경영진은 이것이 AGI를 달성할 수 있는 가장 유망한 방법이라고 생각합니다.

 -->
